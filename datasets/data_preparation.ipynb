{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80e2196b",
   "metadata": {},
   "source": [
    "# This is the part where the data handling pipeline is created.\n",
    "- here data will be turned into json format for spacy training.\n",
    "- Pandas will be used for cleaning and preparation of the data.\n",
    "- Then they will be put through preatrained spacy model and then NER will be created."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5261dd",
   "metadata": {},
   "source": [
    "## Step 1. Importing Libraries/Frameworks\n",
    "- Formatting of the datasets into one format (JSON).\n",
    "- save it in a docbin format\n",
    "- Then feed it to a NER model (spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c896c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from pathlib import Path\n",
    "import chardet\n",
    "import ftfy\n",
    "from functools import reduce\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610b052b",
   "metadata": {},
   "source": [
    "### Open a new directory to save the prepared data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4307e507",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = Path(\"NER_ready_data\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f3c2c4",
   "metadata": {},
   "source": [
    "## Step 2. Handling Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2e452f",
   "metadata": {},
   "source": [
    "### 2.1 Preparing CSV data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f05d02a",
   "metadata": {},
   "source": [
    "#### Loading datasets\n",
    "\n",
    "- Since all of them has unique structure and naming I will open them one by one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51abfe4",
   "metadata": {},
   "source": [
    "#### Global Functions to make the data more consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4cc327ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "def lowercase(data):\n",
    "    df = pd.read_csv(data, encoding=\"utf-8\")\n",
    "    for column in df.columns:\n",
    "        df[column] = df[column].astype(str).str.lower()\n",
    "    return df\n",
    "\n",
    "def text_standardizer(data):\n",
    "    bachelors = [\"bs\", \"bsc\", \"\"]\n",
    "    masters = []\n",
    "    mapping = {\n",
    "        bachelors: \"bachelor's\",\n",
    "        masters: \"master's\"\n",
    "    }\n",
    "\n",
    "path_of_clean_data = os.path.join(os.getcwd(), \"NER_ready_data\")\n",
    "print(len(os.listdir(path_of_clean_data)))\n",
    "for i in range(len(os.listdir(path_of_clean_data))):\n",
    "    lowercase(os.path.join(path_of_clean_data, f\"dataset{i+1}.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f26fde5",
   "metadata": {},
   "source": [
    "#### Dataset 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2a5212c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(os.getcwd(), \"ahmedheakl_resume_atlas.csv\")\n",
    "df = pd.read_csv(data_path, index_col='Unnamed: 0')\n",
    "df['Category'].unique()\n",
    "it_jobs_list = [\"Blockchain\", \"Data Science\", \"Database\", \"DevOps\", \"DotNet Developer\", \"ETL Developer\", \"Information Technology\", \"Java Developer\", \n",
    "                \"Network Security Engineer\", \"Python Developer\", \"React Developer\", \"SAP Developer\", \"SQL Developer\", \"Web Designing\"]\n",
    "df = df[df['Category'].isin(it_jobs_list)]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.rename(columns={\"Category\": \"category\", \"Text\": \"text\"}, inplace=True)\n",
    "## dataset does not contain empty values so there is no need to do anything more for spaCy training.\n",
    "file_path = out_dir / \"dataset1.csv\"\n",
    "df.to_csv(file_path, index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d06088",
   "metadata": {},
   "source": [
    "#### Dataset 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ceadc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(os.getcwd(), \"InferencePrince555_Resume_data.csv\")\n",
    "df = pd.read_csv(data_path, index_col='Unnamed: 0')\n",
    "\n",
    "def splitter(row):\n",
    "    if not isinstance(row, str):\n",
    "        if pd.isna(row):\n",
    "            row = ''\n",
    "        else:\n",
    "            row = str(row)\n",
    "    match = re.match(r'(^[A-Z\\s]+)\\s(.*)', row)\n",
    "    if match:\n",
    "        title = match.group(1).strip()\n",
    "        cv = match.group(2).strip()\n",
    "        return title, cv\n",
    "    return None, row.strip()\n",
    "\n",
    "source_col = 'Resume_test' if 'Resume_test' in df.columns else ('Resume' if 'Resume' in df.columns else df.columns[0])\n",
    "series = df[source_col].fillna('').astype(str)\n",
    "df[[\"category\", \"text\"]] = series.apply(lambda x: pd.Series(splitter(x)))\n",
    "\n",
    "df = df[[\"category\", \"text\"]]\n",
    "# Save cleaned dataset to NER_ready_data\n",
    "it_job_list = ['SOFTWARE DEVELOPER', 'TECHNOLOGY PROJECT AND PRODUCT MANAGER', 'LEAD SENIOR SAP AUDITOR', 'IT COMPLIANCE AUDITOR', 'I T SUPPORT TECHNICIAN SPECIALIST', 'SENIOR NETWORK SECURITY ENGINEER', 'SOFTWARE ENGINEER', 'GAME DESIGN INTERN', 'IT MANAGER', 'SOFTWARE SUPPORT SPECIALIST', 'DATASTAGE ETL DEVELOPER', 'SENIOR ARCHITECT MDM', 'DATA ANALYST', 'SOFTWARE ENGINEERING CO OP', 'JAVA INTERN', 'OPERATIONS TECHNICIAN', 'SR NETWORK ENGINEER', 'IT SUPPORT OFFICER', 'TEAM LEAD SENIOR ANALYST', 'REGIONAL IT MANAGER', 'QA TEST ANALYST', 'SOFTWARE QUALITY ASSURANCE ANALYST II', 'IT', 'QA QC MANAGER', 'IT CONSULTANT', 'WEB DEVELOPER', 'DATABASE ADMINISTRATOR DATABASE', 'SENIOR JAVA DEVELOPER SENIOR', 'ITDIGITAL SOLUTIONS PROJECT MANAGER', 'PYTHON DEVELOPER', 'SAP SECURITY SPECIALIST GBS SAP', 'UI', 'SYSYTEM ADMINISTRATOR SYSYTEM', 'IT SERVICE DESK TECHNICIAN IT SERVICE DESK TECHNICIAN IT SERVICE DESK TECHNICIAN FISHER INVESTMENTS', 'SYSTEMS ENGINEER', 'SR SOFTWARE DEVELOPER EMPOWER SOFTWARE SR', 'WEB DEVLOPER INTERN WEB DEVLOPER INTERN', 'CYBER SECURITY ANALYST CYBER', 'INFORMATION SECURITY ENGINEER INFORMATION', 'JAVA WEB SERVICESSOA DEVELOPER', 'JAVA DEVELOPER', 'PYTHON AUTOMATION ENGINEER', 'SAP TEACHING ASSISTANT SAP TEACHING ASSISTANT SAP TEACHING ASSISTANT', 'SR SOFTWARE DEVELOPER SR SOFTWARE', 'FRONT END DEVELOPER UX DESIGNER', 'FULL STACK JAVA DEVELOPER FULL STACK', 'SYSTEMS ADMINISTRATOR', 'UX DESIGNER FRONT END DEVELOPER UX DESIGNER', 'INFORMATION SECURITY ANALYST INFORMATION', 'JUNIOR SYSTEMS ADMINISTRATOR JUNIOR', 'NETWORK ENGINEER', 'TACTICAL DATA SYSTEMS ADMINISTRATOR TACTICAL DATA', 'FRONT END DEVELOPER', 'IT SECURITY ENGINEER', 'ITOFFICE SUPPORT SPECIALIST OVATION TECHNOLOGY GROUP', 'SENIOR APPLICATIONS DEVELOPER SENIOR APPLICATIONS', 'IT CONSULTANT DEVELOPER', 'SENIOR SYSTEMS ADMINISTRATOR SENIOR SYSTEMS', 'PRODUCT SUPPORT ENGINEER PRODUCT SUPPORT ENGINEER PRODUCT SUPPORT ENGINER', 'IT PROJECT MANAGER', 'DATABASE ADMINISTRATOR', 'SR IT PROJECT MANAGER SCRUM MASTER SR', 'IT PROJECT ANALYST', 'IOS', 'FREELANCE WEB DEVELOPER FREELANCE', 'ASSOCIATE NETWORK ADMINISTRATOR ASSOCIATE NETWORK', 'WEB MANAGER', 'RESEARCH DATABASE ADMINISTRATOR RESEARCH', 'IT SECURITY ANALYST', 'SENIOR WEB DEVELOPER SENIOR WEB', 'IT MANAGER IT MANAGER WEB DEVELOPER', 'SCRUM MASTER AGILE SCRUM MASTER AGILE SCRUM MASTER AGILE', 'SYSTEMS ANALYST', 'FRONT END WEB DEVELOPER', 'REMOTE SQL SERVER DATABASE ADMINISTRATOR REMOTE SQL SERVER', 'SR PENETRATION TESTER SR PENETRATION TESTER', 'SENIOR INFORMATION TECHNOLOGY IT PROJECT MANAGER SENIOR INFORMATION TECHNOLOGY', 'SENIOR SOFTWARE DEVELOPER SENIOR', 'IT QA', 'DESKTOP ADMINISTRATOR DESKTOP', 'SENIOR FRONT END WEB DEVELOPER SENIOR', 'STAFF UX DESIGNER STAFF UX DESIGNER UX DESIGNER MICROSOFT POWERAPPS']\n",
    "mapped_vals = { \"SOFTWARE DEVELOPER\": \"Software Developer\", \"TECHNOLOGY PROJECT AND PRODUCT MANAGER\": \"Technology Project and Product Manager\", \"LEAD SENIOR SAP AUDITOR\": \"Lead Senior SAP Auditor\", \"IT COMPLIANCE AUDITOR\": \"IT Compliance Auditor\", \"I T SUPPORT TECHNICIAN SPECIALIST\": \"IT Support Technician / Specialist\", \"SENIOR NETWORK SECURITY ENGINEER\": \"Senior Network Security Engineer\", \"SOFTWARE ENGINEER\": \"Software Engineer\", \"GAME DESIGN INTERN\": \"Game Design Intern\", \"IT MANAGER\": \"IT Manager\", \"SOFTWARE SUPPORT SPECIALIST\": \"Software Support Specialist\", \"DATASTAGE ETL DEVELOPER\": \"DataStage ETL Developer\", \"SENIOR ARCHITECT MDM\": \"Senior Architect MDM\", \"DATA ANALYST\": \"Data Analyst\", \"SOFTWARE ENGINEERING CO OP\": \"Software Engineering Co-op\", \"JAVA INTERN\": \"Java Intern\", \"OPERATIONS TECHNICIAN\": \"Operations Technician\", \"SR NETWORK ENGINEER\": \"Senior Network Engineer\", \"IT SUPPORT OFFICER\": \"IT Support Officer\", \"TEAM LEAD SENIOR ANALYST\": \"Team Lead Senior Analyst\", \"REGIONAL IT MANAGER\": \"Regional IT Manager\", \"QA TEST ANALYST\": \"QA Test Analyst\", \"SOFTWARE QUALITY ASSURANCE ANALYST II\": \"Software Quality Assurance Analyst II\", \"IT\": \"IT\", \"QA QC MANAGER\": \"QA/QC Manager\", \"IT CONSULTANT\": \"IT Consultant\", \"WEB DEVELOPER\": \"Web Developer\", \"DATABASE ADMINISTRATOR DATABASE\": \"Database Administrator\", \"SENIOR JAVA DEVELOPER SENIOR\": \"Senior Java Developer\", \"ITDIGITAL SOLUTIONS PROJECT MANAGER\": \"IT Digital Solutions Project Manager\", \"PYTHON DEVELOPER\": \"Python Developer\", \"SAP SECURITY SPECIALIST GBS SAP\": \"SAP Security Specialist\", \"UI\": \"UI\", \"SYSYTEM ADMINISTRATOR SYSYTEM\": \"Systems Administrator\", \"IT SERVICE DESK TECHNICIAN IT SERVICE DESK TECHNICIAN IT SERVICE DESK TECHNICIAN FISHER INVESTMENTS\": \"IT Service Desk Technician\", \"SYSTEMS ENGINEER\": \"Systems Engineer\", \"SR SOFTWARE DEVELOPER EMPOWER SOFTWARE SR\": \"Senior Software Developer\", \"WEB DEVLOPER INTERN WEB DEVLOPER INTERN\": \"Web Developer Intern\", \"CYBER SECURITY ANALYST CYBER\": \"Cyber Security Analyst\", \"INFORMATION SECURITY ENGINEER INFORMATION\": \"Information Security Engineer\", \"JAVA WEB SERVICESSOA DEVELOPER\": \"Java Web Services SOA Developer\", \"JAVA DEVELOPER\": \"Java Developer\", \"PYTHON AUTOMATION ENGINEER\": \"Python Automation Engineer\", \"SAP TEACHING ASSISTANT SAP TEACHING ASSISTANT SAP TEACHING ASSISTANT\": \"SAP Teaching Assistant\", \"SR SOFTWARE DEVELOPER SR SOFTWARE\": \"Senior Software Developer\", \"FRONT END DEVELOPER UX DESIGNER\": \"Front End Developer / UX Designer\", \"FULL STACK JAVA DEVELOPER FULL STACK\": \"Full Stack Java Developer\", \"SYSTEMS ADMINISTRATOR\": \"Systems Administrator\", \"UX DESIGNER FRONT END DEVELOPER UX DESIGNER\": \"UX Designer / Front End Developer\", \"INFORMATION SECURITY ANALYST INFORMATION\": \"Information Security Analyst\", \"JUNIOR SYSTEMS ADMINISTRATOR JUNIOR\": \"Junior Systems Administrator\", \"NETWORK ENGINEER\": \"Network Engineer\", \"TACTICAL DATA SYSTEMS ADMINISTRATOR TACTICAL DATA\": \"Tactical Data Systems Administrator\", \"FRONT END DEVELOPER\": \"Front End Developer\", \"IT SECURITY ENGINEER\": \"IT Security Engineer\", \"ITOFFICE SUPPORT SPECIALIST OVATION TECHNOLOGY GROUP\": \"IT Office Support Specialist\", \"SENIOR APPLICATIONS DEVELOPER SENIOR APPLICATIONS\": \"Senior Applications Developer\", \"IT CONSULTANT DEVELOPER\": \"IT Consultant / Developer\", \"SENIOR SYSTEMS ADMINISTRATOR SENIOR SYSTEMS\": \"Senior Systems Administrator\", \"PRODUCT SUPPORT ENGINEER PRODUCT SUPPORT ENGINEER PRODUCT SUPPORT ENGINER\": \"Product Support Engineer\", \"IT PROJECT MANAGER\": \"IT Project Manager\", \"DATABASE ADMINISTRATOR\": \"Database Administrator\", \"SR IT PROJECT MANAGER SCRUM MASTER SR\": \"Senior IT Project Manager / Scrum Master\", \"IT PROJECT ANALYST\": \"IT Project Analyst\", \"IOS\": \"iOS Developer\", \"FREELANCE WEB DEVELOPER FREELANCE\": \"Freelance Web Developer\", \"ASSOCIATE NETWORK ADMINISTRATOR ASSOCIATE NETWORK\": \"Associate Network Administrator\", \"WEB MANAGER\": \"Web Manager\", \"RESEARCH DATABASE ADMINISTRATOR RESEARCH\": \"Research Database Administrator\", \"IT SECURITY ANALYST\": \"IT Security Analyst\", \"SENIOR WEB DEVELOPER SENIOR WEB\": \"Senior Web Developer\", \"IT MANAGER IT MANAGER WEB DEVELOPER\": \"IT Manager / Web Developer\", \"SCRUM MASTER AGILE SCRUM MASTER AGILE SCRUM MASTER AGILE\": \"Scrum Master (Agile)\", \"SYSTEMS ANALYST\": \"Systems Analyst\", \"FRONT END WEB DEVELOPER\": \"Front End Web Developer\", \"REMOTE SQL SERVER DATABASE ADMINISTRATOR REMOTE SQL SERVER\": \"Remote SQL Server Database Administrator\", \"SR PENETRATION TESTER SR PENETRATION TESTER\": \"Senior Penetration Tester\", \"SENIOR INFORMATION TECHNOLOGY IT PROJECT MANAGER SENIOR INFORMATION TECHNOLOGY\": \"Senior IT Project Manager\", \"SENIOR SOFTWARE DEVELOPER SENIOR\": \"Senior Software Developer\", \"IT QA\": \"IT QA Analyst\", \"DESKTOP ADMINISTRATOR DESKTOP\": \"Desktop Administrator\", \"SENIOR FRONT END WEB DEVELOPER SENIOR\": \"Senior Front End Web Developer\", \"STAFF UX DESIGNER STAFF UX DESIGNER UX DESIGNER MICROSOFT POWERAPPS\": \"Staff UX Designer\" }\n",
    "df[\"category\"] = df[\"category\"].map(mapped_vals).fillna(df[\"category\"])\n",
    "df = df[df[\"category\"].isin(it_job_list)]\n",
    "\n",
    "file_path = out_dir / \"dataset2.csv\"\n",
    "df.to_csv(file_path, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7142bd78",
   "metadata": {},
   "source": [
    "#### Dataset 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac4653f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Bytes: b',Category,Resume\\n0,Data Science,\"Skills * Programming Languages: Python (pandas, numpy, scipy, scikit-learn, matplotlib), Sql, Java, JavaScript/JQuery. * Machine learning: Regression, SVM, Na\\xc3\\x83\\xc2\\xafve Ba'\n",
      "has utf-8 BOM: False\n",
      "Contains NUL bytes: False\n"
     ]
    }
   ],
   "source": [
    "p = os.path.join(os.getcwd(), \"Sachinkelenjaguri_resume_Dataset.csv\")\n",
    "with open(p, \"rb\") as fh:\n",
    "    head = fh.read(200)\n",
    "print(\"First Bytes:\", head)\n",
    "print(\"has utf-8 BOM:\", head.startswith(b\"\\xef\\xbb\\xbf\"))\n",
    "\n",
    "has_nul = b\"\\x00\" in head\n",
    "print(\"Contains NUL bytes:\", has_nul)\n",
    "\n",
    "df = pd.read_csv(\"Sachinkelenjaguri_resume_Dataset.csv\", encoding=\"utf-8\", low_memory=False, index_col='Unnamed: 0')\n",
    "df['Category'] = df['Category'].astype(str).apply(ftfy.fix_text)\n",
    "df[\"Resume\"] = df[\"Resume\"].astype(str).apply(ftfy.fix_text)\n",
    "\n",
    "df.rename(columns={\"Category\": \"category\", \"Resume\": \"text\"}, inplace=True)\n",
    "\n",
    "data_path = out_dir / \"dataset3.csv\"\n",
    "df.to_csv(data_path, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1e2bbd",
   "metadata": {},
   "source": [
    "### 2.2 handling data from the directories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4615a18",
   "metadata": {},
   "source": [
    "#### Dataset 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00a5297e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = os.path.join(os.getcwd(), \"wahib04/multilabel-resume-dataset/versions/1/data.csv\")\n",
    "df = pd.read_csv(dataset_path, encoding='utf-8')\n",
    "df = df.drop(columns='Label').reset_index(drop=True)\n",
    "\n",
    "def splitter(row):\n",
    "    if not isinstance(row, str):\n",
    "        row = '' if pd.isna(row) else str(row)\n",
    "    if '-' in row:\n",
    "        title, rest = row.split('-', 1)\n",
    "        return title.strip(), rest.strip()\n",
    "    return None, row.strip()\n",
    "series = df[\"Resume\"]\n",
    "df[[\"category\", \"text\"]] = series.apply(lambda x: pd.Series(splitter(x)))\n",
    "df = df[[\"category\", \"text\"]]\n",
    "\n",
    "data_path = out_dir / \"dataset4.csv\"\n",
    "df.to_csv(data_path, index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037d147c",
   "metadata": {},
   "source": [
    "#### Dataset 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77d3d136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['05_person_skills.csv', '03_education.csv', '06_skills.csv', '04_experience.csv', '02_abilities.csv', '01_people.csv']\n"
     ]
    }
   ],
   "source": [
    "dataset_path = os.path.join(os.getcwd(), \"suriyaganesh/resume-dataset-structured/versions/2\")\n",
    "print(os.listdir(dataset_path))\n",
    "\n",
    "df1_path = os.path.join(dataset_path, \"01_people.csv\")\n",
    "df1 = pd.read_csv(df1_path)\n",
    "\n",
    "df2_path = os.path.join(dataset_path, \"02_abilities.csv\")\n",
    "df2 = pd.read_csv(df2_path)\n",
    "\n",
    "df3_path = os.path.join(dataset_path, \"03_education.csv\")\n",
    "df3 = pd.read_csv(df3_path)\n",
    "\n",
    "df4_path = os.path.join(dataset_path, \"04_experience.csv\")\n",
    "df4 = pd.read_csv(df4_path)\n",
    "\n",
    "df5_path = os.path.join(dataset_path, \"05_person_skills.csv\")\n",
    "df5 = pd.read_csv(df5_path)\n",
    "\n",
    "df6_path = os.path.join(dataset_path, \"06_skills.csv\")\n",
    "df6 = pd.read_csv(df6_path)\n",
    "\n",
    "merged_1 = df1.merge(df2, on=\"person_id\", how=\"inner\")\n",
    "merged_1 = merged_1.drop(columns=[\"email\", \"phone\", \"linkedin\"]).reset_index(drop=True)\n",
    "\n",
    "rest_dfs = [df3, df4, df5]\n",
    "merged_2 = reduce(lambda left, right: pd.merge(left, right, on=\"person_id\", how=\"inner\"), rest_dfs)\n",
    "merged_2 = merged_2.drop(columns=\"location_x\").reset_index(drop=True)\n",
    "\n",
    "merged_3 = merged_2.merge(df6, on=\"skill\", how=\"inner\")\n",
    "\n",
    "merged_3[\"program\"] = merged_3[\"program\"].fillna(\"Not attended to University\")\n",
    "\n",
    "merged_reduced = merged_3.groupby([\"person_id\"]).agg({\n",
    "    \"program\": lambda x: ', '.join(sorted(set(x.dropna().astype(str)))), \n",
    "    \"title\": lambda x: ', '.join(sorted(set(x.dropna().astype(str)))), \n",
    "    \"firm\": lambda x: ', '.join(sorted(set(x.dropna().astype(str)))), \n",
    "    \"skill\": lambda x: ', '.join(sorted(set(x.dropna().astype(str))))}\n",
    "    ).reset_index()\n",
    "\n",
    "merged_reduced[\"resume\"] = np.where(\n",
    "    merged_reduced[\"program\"] != \"Not attended to University\",\n",
    "    \"Candidate \" + merged_reduced[\"person_id\"].astype(str)\n",
    "    + \", has completed \" + merged_reduced[\"program\"]\n",
    "    + \", and worked in the following positions: \" + merged_reduced[\"title\"]\n",
    "    + \", at the following companies: \" + merged_reduced[\"firm\"]\n",
    "    + \", has skills: \" + merged_reduced[\"skill\"],\n",
    "    \n",
    "    \"Candidate \" + merged_reduced[\"person_id\"].astype(str)\n",
    "    + \", has not attended university, and worked in the following positions: \"\n",
    "    + merged_reduced[\"title\"]\n",
    "    + \", at the following companies: \" + merged_reduced[\"firm\"]\n",
    "    + \", has skills: \" + merged_reduced[\"skill\"]\n",
    ")\n",
    "\n",
    "final_set = merged_reduced[[\"title\", \"resume\"]]\n",
    "\n",
    "final_set.rename(columns={\"title\" : \"category\", \"resume\" : \"text\"})\n",
    "\n",
    "final_path = out_dir / \"dataset5.csv\"\n",
    "final_set.to_csv(final_path, index=False, encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Job-Recommender (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
